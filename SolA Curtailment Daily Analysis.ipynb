{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc659669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import pytz #for timezone calculation\n",
    "import math\n",
    "import matplotlib.dates as md\n",
    "import gc\n",
    "import os\n",
    "%matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9638991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Global parameters for fonts & sizes =================\n",
    "font_size = 10\n",
    "rc={'font.size': font_size, 'axes.labelsize': font_size, 'legend.fontsize': font_size, \n",
    "    'axes.titlesize': font_size, 'xtick.labelsize': font_size, 'ytick.labelsize': font_size}\n",
    "plt.rcParams.update(**rc)\n",
    "plt.rc('font', weight='bold')\n",
    " \n",
    "# For label titles\n",
    "fontdict={'fontsize': font_size, 'fontweight' : 'bold'}\n",
    "# can add in above dictionary: 'verticalalignment': 'baseline' \n",
    "\n",
    "style = 'ggplot' # choose a style from the above options\n",
    "plt.style.use(style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f7f563d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VWATT CLASSES AND FUNCTIONS\n",
    "\n",
    "# SITE AND CIRCUIT CLASSES USED TO ORGANISE THE SITES TELEMETRY AND META DATA FOR EASE IN PROCESSING\n",
    "\n",
    "class Site:\n",
    "  def __init__(self, site_id, s_postcode, pv_install_date, ac_cap_w, dc_cap_w, inverter_manufacturer, inverter_model):\n",
    "    self.site_id = site_id\n",
    "    self.s_postcode = s_postcode\n",
    "    self.pv_install_date = pv_install_date\n",
    "    self.ac_cap_w = ac_cap_w\n",
    "    self.dc_cap_w = dc_cap_w\n",
    "    self.inverter_manufacturer = inverter_manufacturer\n",
    "    self.inverter_model = inverter_model\n",
    "    self.c_id_data = {}\n",
    "\n",
    "class Circuit:\n",
    "  def __init__(self, c_id, site_id, con_type, polarity):\n",
    "    self.c_id = c_id\n",
    "    self.con_type = con_type\n",
    "    self.polarity = polarity\n",
    "    self.day_data = {}\n",
    "    \n",
    "# ADJUST FORMATE FOR TIMESTAMP STRINGS\n",
    "def Get_timestamp_date_string(string):\n",
    "    x = string.split(\"_\")\n",
    "    return x[0] + \"-\" + x[1]\n",
    "\n",
    "# SEPARATE THE BoM GHI DATA FILES PER DAY TO SEARCH FOR CLEAR SKY DAYS\n",
    "def Separate_ghi_data(month, ghi):\n",
    "    ghi['ts'] = pd.to_datetime(pd.DataFrame({'year': ghi['Year Month Day Hours Minutes in YYYY'].values,\n",
    "                                                    'month': ghi['MM'],\n",
    "                                                    'day': ghi['DD'],\n",
    "                                                    'hour': ghi['HH24'],\n",
    "                                                    'minute': ghi['MI format in Local standard time']}))\n",
    "    ghi.rename(columns={'Mean global irradiance (over 1 minute) in W/sq m': 'mean_ghi',\n",
    "                        'Minimum 1 second global irradiance (over 1 minute) in W/sq m': 'min_ghi',\n",
    "                        'Maximum 1 second global irradiance (over 1 minute) in W/sq m': 'max_ghi',\n",
    "                        'Standard deviation of global irradiance (over 1 minute) in W/sq m': 'sd_ghi',\n",
    "                        'Uncertainty in mean global irradiance (over 1 minute) in W/sq m': 'uncertainty_ghi'},\n",
    "               inplace=True)\n",
    "    key_ghi_values = ghi[['ts', 'mean_ghi', 'min_ghi', 'max_ghi', 'sd_ghi', 'uncertainty_ghi']].copy()\n",
    "    key_ghi_values['mean_ghi'] = key_ghi_values.apply(lambda row: String_to_Float(row['mean_ghi']), axis=1)\n",
    "    key_ghi_values['min_ghi'] = key_ghi_values.apply(lambda row: String_to_Float(row['min_ghi']), axis=1)\n",
    "    key_ghi_values['max_ghi'] = key_ghi_values.apply(lambda row: String_to_Float(row['max_ghi']), axis=1)\n",
    "\n",
    "\n",
    "    combined_ghi_dict = {}\n",
    "    month_number = int(month.split('-')[1])\n",
    "\n",
    "    for day in range(1, Days_in_month(month_number) + 1):\n",
    "        day_string = str(day)\n",
    "        if day < 10:\n",
    "            day_string = \"0\" + day_string\n",
    "\n",
    "        date = month + \"-\" + day_string\n",
    "        df = key_ghi_values.loc[key_ghi_values['ts'] > date + \" 00:00:01\"]\n",
    "        df = df.loc[key_ghi_values['ts'] < date + \" 23:59:01\"]\n",
    "\n",
    "        combined_ghi_dict[date] = df\n",
    "\n",
    "    return combined_ghi_dict\n",
    "\n",
    "# REMOVE SPACES AND CHECK IF VALUE NULL\n",
    "def String_to_Float(string):\n",
    "    x = string.strip()\n",
    "    if not x:\n",
    "        x = 0\n",
    "    else:\n",
    "        x = float(x)\n",
    "    return x\n",
    "\n",
    "def Days_in_month(month):\n",
    "        switcher = {\n",
    "            1: 31,\n",
    "            2: 29,\n",
    "            3: 31,\n",
    "            4: 30,\n",
    "            5: 31,\n",
    "            6: 30,\n",
    "            7: 31,\n",
    "            8: 31,\n",
    "            9: 30,\n",
    "            10: 31,\n",
    "            11: 30,\n",
    "            12: 31,\n",
    "        }\n",
    "        return switcher.get(month, 0)\n",
    "    \n",
    "# LOOK FOR FOR SUDDEN VARIATIONS IN SOLAR INSOLATION DATA WHICH INDICATES LIKELY CLOUD COVER, AS OPPOSED TO CLEAR PARABOLIC SHAPE OF CLEAR SKY DAY GHI CURVES\n",
    "def Detect_clear_sky_day(ghi_df, min_max_ghi):\n",
    "    df_daytime = ghi_df.loc[ghi_df['mean_ghi'] > 0]\n",
    "\n",
    "    collective_change = 0\n",
    "    ghi_list = df_daytime.mean_ghi.tolist()\n",
    "\n",
    "    for i in range(len(ghi_list)-1):\n",
    "        collective_change += abs(ghi_list[i+1] - ghi_list[i])\n",
    "\n",
    "    if len(df_daytime.index) == 0:\n",
    "        return False, 0\n",
    "    \n",
    "    average_delta_y = collective_change/len(df_daytime.index)\n",
    "\n",
    "    if average_delta_y < 5 and max(ghi_df.mean_ghi) > min_max_ghi:\n",
    "        return True, average_delta_y\n",
    "    else:\n",
    "        return False, average_delta_y\n",
    "    \n",
    "def Get_telemetry_string(string):\n",
    "    x = string.split(\"_\")\n",
    "    return x[0] + x[1]\n",
    "\n",
    "def Filter_data_clear_sky_days(data, clear_sky_days):\n",
    "    filtered_df = None\n",
    "    \n",
    "    for day in clear_sky_days:\n",
    "        tmp_df = data.loc[data['utc_tstamp'] > Convert_SA_time_to_UTC(day + \" 00:00:01\")]\n",
    "        tmp_df = tmp_df.loc[tmp_df['utc_tstamp'] < Convert_SA_time_to_UTC(day + \" 23:59:01\")]\n",
    "\n",
    "        if filtered_df is None:\n",
    "            filtered_df = tmp_df\n",
    "        else:\n",
    "            filtered_df = filtered_df.append(tmp_df, ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def Convert_SA_time_to_UTC(sa_time):\n",
    "    timeFormat = \"%Y-%m-%d %H:%M:%S\"\n",
    "    x = datetime.strptime(sa_time, timeFormat)\n",
    "    sa_local_time = pytz.timezone('Australia/Adelaide')\n",
    "    utc_time = pytz.utc\n",
    "    sa_moment = sa_local_time.localize(x, is_dst=None)\n",
    "    utc_time = sa_moment.astimezone(utc_time)\n",
    "    a = utc_time.strftime(timeFormat)\n",
    "    return a\n",
    "\n",
    "# ORGANISES ALL TELEMETRY IN THE HIERARCHY: SITE->CIRCUITS->DAYS_OF_DATA\n",
    "def Organise_sites(clear_sky_days, site_id_list, month, inverter_telemetry, site_details, cicuit_details):  # add gen data\n",
    "\n",
    "    overall_site_organiser = {}\n",
    "\n",
    "    for site_id in site_id_list:\n",
    "        if site_id not in site_details.site_id.unique():\n",
    "            continue\n",
    "        overall_site_organiser[site_id] = Organise_individual_site(clear_sky_days, site_id, month, inverter_telemetry,\n",
    "                                        site_details.loc[site_details['site_id'] == site_id],\n",
    "                                        cicuit_details.loc[\n",
    "                                            cicuit_details['site_id'] == site_id])\n",
    "\n",
    "    return overall_site_organiser\n",
    "\n",
    "\n",
    "def Organise_individual_site(clear_sky_days, site_id, month, inverter_telemetry, site_details, cicuit_details):\n",
    "    site = Site(site_id, site_details.iloc[0].s_postcode, site_details.iloc[0].pv_install_date,\n",
    "                site_details.iloc[0].ac_cap_w,\n",
    "                site_details.iloc[0].dc_cap_w, site_details.iloc[0].inverter_manufacturer,\n",
    "                site_details.iloc[0].inverter_model)\n",
    "\n",
    "    for row in cicuit_details.iterrows():\n",
    "        c_id = row[1].c_id\n",
    "        site.c_id_data[c_id] = Organise_individual_circuit(clear_sky_days, c_id, site_id, month,\n",
    "                                inverter_telemetry.loc[inverter_telemetry['c_id'] == c_id],\n",
    "                                row[1].con_type, row[1].polarity)\n",
    "\n",
    "    return site\n",
    "\n",
    "\n",
    "def Organise_individual_circuit(clear_sky_days, c_id, site_id, month, inverter_telemetry, con_type, polarity):\n",
    "    circuit = Circuit(c_id, site_id, con_type, polarity)\n",
    "    inverter_telemetry['ts'] = inverter_telemetry.apply(lambda row: Convert_to_SA_time(row['utc_tstamp']), axis=1)\n",
    "\n",
    "\n",
    "    month_number = int(month.split('-')[1])\n",
    "    for day in clear_sky_days:\n",
    "\n",
    "        circuit.day_data[day] = Organise_individual_day(day, inverter_telemetry)\n",
    "\n",
    "    return circuit\n",
    "\n",
    "\n",
    "def Organise_individual_day(date, inverter_telemetry):\n",
    "    inverter_telemetry = inverter_telemetry.loc[inverter_telemetry['ts'] > date + \" 00:00:01\"]\n",
    "    inverter_telemetry = inverter_telemetry.loc[inverter_telemetry['ts'] < date + \" 23:59:01\"]    \n",
    "    return inverter_telemetry.sort_values('ts', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='first', ignore_index=False, key=None)\n",
    "\n",
    "def Find_over_voltage_sites(v, clear_sky_data, cicuit_details):\n",
    "    site_id_list_ov = {}\n",
    "    # Determine subsets of sites that experience over voltages to different extents for later selection\n",
    "    testVs = list(range(235, 256))\n",
    "    for i in testVs:\n",
    "        site_id_list_ov[i] = []\n",
    "\n",
    "    c_id_list = clear_sky_data.c_id.unique()\n",
    "\n",
    "    for c_id in c_id_list:\n",
    "        C_id_to_site_id(c_id, cicuit_details)\n",
    "\n",
    "    for c_id in c_id_list:\n",
    "\n",
    "        df = clear_sky_data.loc[clear_sky_data['c_id'] == c_id]\n",
    "        if len(df.index) == 0:\n",
    "            continue\n",
    "\n",
    "        df = df.loc[df['power'] > 0]\n",
    "        if len(df.index) == 0:\n",
    "            continue\n",
    "\n",
    "        maxV = max(df.voltage)\n",
    "\n",
    "        site_id = C_id_to_site_id(c_id, cicuit_details)\n",
    "\n",
    "        for i in testVs:\n",
    "            if maxV > i:\n",
    "                if c_id not in site_id_list_ov[i]:\n",
    "                    site_id_list_ov[i].append(site_id)\n",
    "\n",
    "    for i in testVs:\n",
    "        print(\"Length vMax > \" + str(i) + \": \" + str(len(site_id_list_ov[i])))\n",
    "\n",
    "    return site_id_list_ov\n",
    "\n",
    "# REUTRN THE SITE ID THAT CORRESPONDS TO A GIVEN CIRCUIT ID\n",
    "def C_id_to_site_id(c_id, cicuit_details):\n",
    "    return cicuit_details.loc[cicuit_details['c_id'] == c_id].iloc[0].site_id\n",
    "\n",
    "# CONVERT TIMESTAMP STRINGS FROM UTC TO LOCAL SOUTH AUSTRALIA TIME, TODO: ADJUST FOR TELEMETRY ANALYSIS IN OTHER CITIES\n",
    "def Convert_to_SA_time(utc_tstamp):\n",
    "    timeFormat1 = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    timeFormat2 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    x = datetime.strptime(utc_tstamp, timeFormat1)\n",
    "    adelaide_local_time = pytz.timezone('Australia/Adelaide')\n",
    "    utc_time = pytz.utc\n",
    "    utc_moment = utc_time.localize(x, is_dst=None)\n",
    "    adelaide_local_time = utc_moment.astimezone(adelaide_local_time)\n",
    "    a = adelaide_local_time.strftime(timeFormat2)\n",
    "    return a\n",
    "\n",
    "# ASSESS AGGREGATED V-WATT DATA FOR A SITE\n",
    "def Assess_Volt_Watt_behaviour_site(site, clear_sky_days, overall_volt_watt_dict):\n",
    "\n",
    "    for c_id in site.c_id_data.keys():\n",
    "        circuit = site.c_id_data[c_id]\n",
    "        Assess_Volt_Watt_behaviour_circuit(circuit, clear_sky_days, site.dc_cap_w, site.ac_cap_w, overall_volt_watt_dict)\n",
    "\n",
    "def Assess_Volt_Watt_behaviour_circuit(circuit, clear_sky_days, dc_cap_w, ac_cap_w, overall_volt_watt_dict):\n",
    "    \n",
    "    for date in clear_sky_days:\n",
    "        voltArray, relativeWattArray, filteredTimeArray, filteredPowerArray = Append_Volt_Watt_behaviour_data(circuit.day_data[date], circuit.c_id, date, ac_cap_w)\n",
    "        if voltArray is not None:\n",
    "            \n",
    "            Display_day(circuit.c_id, date, circuit.day_data[date], ac_cap_w, voltArray, relativeWattArray, filteredTimeArray, filteredPowerArray)\n",
    "            if circuit.c_id not in overall_volt_watt_dict.keys():\n",
    "                overall_volt_watt_dict[circuit.c_id] = {\"v\": [], 'p': [], 'd': 0}\n",
    "\n",
    "            overall_volt_watt_dict[circuit.c_id]['v'] += voltArray\n",
    "            overall_volt_watt_dict[circuit.c_id]['p'] += relativeWattArray\n",
    "            overall_volt_watt_dict[circuit.c_id]['d'] += 1\n",
    "    print(\"Length of sites determined to be assessable: \" + str(len(overall_volt_watt_dict.keys())))\n",
    "\n",
    "# ORGANISE DATA FOR DETERMINING COMPLIANCE FUNCTION BELOW\n",
    "def Append_Volt_Watt_behaviour_data(df, c_id, date, dc_cap_w):    \n",
    "\n",
    "    if df is None:\n",
    "        return None, None, None, None\n",
    "\n",
    "    if len(df.index) == 0:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    if max(df.power) < 0.3:\n",
    "        return None, None, None, None\n",
    "\n",
    "    df = SliceEndOffDF(df)\n",
    "\n",
    "    df = df.loc[df['power'] > 300]\n",
    "\n",
    "    if len(df.index) < 20:\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Filter power data for only 'uncurtailed instances' (estimation as it is unknown when inverter is actively curtailing output)\n",
    "    powerArray, timeArray = FilterPowerData(df)\n",
    "\n",
    "    # Filter data for limited gradients, useful in creating more accurate polyfits, as determined by visual verification\n",
    "    powerArray, timeArray = FilterDataLimitedGradients(powerArray, timeArray)\n",
    "\n",
    "    if powerArray is None or len(powerArray) < 20:\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Get polyfit estimation\n",
    "    polyfit = GetPolyfit(getDateTimeList(timeArray), powerArray, 2)\n",
    "\n",
    "    # Simple filter for very high and low values to aid in displaying data in figures\n",
    "    filteredPowerArray, filteredTimeArray = FilterArray(polyfit(getDateTime(df)), getDateTime(df), 100000, 0)\n",
    "    \n",
    "    filteredPowerArray = Change_W_to_kW(filteredPowerArray)\n",
    "    \n",
    "    maxPower = max(filteredPowerArray)\n",
    "    \n",
    "\n",
    "    maxCompliance = 0\n",
    "    bestVWLimit = 248\n",
    "    bestTotalPoints = 1\n",
    "\n",
    "    # Determine which data points are of interest for compliance by comparing actual output vs polyfit predicted output, and voltage conditions\n",
    "    # Ie. W-Watt curtailment can only occur when P_modelled > P_max_allowed.\n",
    "    complianceCount, voltArrayCompliance, timeArrayCompliance, absoluteWattArrayCompliance, relativeWattArrayCompliance, successfulRelativeWattArray, successfulVoltArray = DetermineCompliance(\n",
    "        polyfit, df, dc_cap_w, 248)\n",
    "    maxVoltWattTimeArray, maxVoltWattPowerArray = getMaxVoltWattCurve(dc_cap_w, df, 249)\n",
    "\n",
    "\n",
    "    if len(voltArrayCompliance) > 0:\n",
    "        return voltArrayCompliance, relativeWattArrayCompliance, filteredTimeArray, filteredPowerArray\n",
    "\n",
    "    return None, None, None, None\n",
    "\n",
    "def SliceEndOffDF(df):\n",
    "    if df is None or len(df.index) == 0:\n",
    "        return None\n",
    "\n",
    "    tmpDF = df.loc[df['power'] > 0]\n",
    "    if len(tmpDF.index) == 0:\n",
    "        return None\n",
    "\n",
    "    startTime = tmpDF.iloc[0].ts\n",
    "    endTime = tmpDF.iloc[len(tmpDF.index) - 1].ts\n",
    "\n",
    "    df = df.loc[df['ts'] > startTime]\n",
    "    df = df.loc[df['ts'] < endTime]\n",
    "\n",
    "    return df\n",
    "\n",
    "# FILTER POWER DATA TO INCLUDE ONLY INCREASING VALUES FROM EACH SIDES (WHERE SIDES ARE DETERMINED BY EITHER SIDE OF THE MAX POWER VALUE)\n",
    "def FilterPowerData(graphDF):\n",
    "    if len(graphDF.index) == 0:\n",
    "        return None, None\n",
    "\n",
    "    maxDailyPower = max(graphDF.power)\n",
    "\n",
    "    if len(graphDF.loc[graphDF['power'] == maxDailyPower].index) > 1:\n",
    "        return None, None\n",
    "\n",
    "    filterArray1 = []\n",
    "    filterArray2 = []\n",
    "    powerArray = graphDF.power\n",
    "    timeArray = graphDF.ts\n",
    "\n",
    "    halfFlag = True  # True is first half, False is second half\n",
    "    waterMark = 0\n",
    "\n",
    "    for currPower in powerArray:\n",
    "\n",
    "        # IF currPower IS GREATER THAN waterMark (LAST HIGHEST VALUE) THEN INCLUDE currPower AND INCREASE waterMark\n",
    "        if currPower > waterMark:\n",
    "            waterMark = currPower\n",
    "            filterArray1.append(True)\n",
    "        else:\n",
    "            filterArray1.append(False)\n",
    "\n",
    "        if currPower == maxDailyPower:\n",
    "            break\n",
    "\n",
    "    waterMark = 0\n",
    "\n",
    "    # PERFORM SAME FILTER ON SECOND SIDE OF POWER ARRAY\n",
    "    for currPower in powerArray.iloc[::-1]:\n",
    "\n",
    "        if currPower == maxDailyPower:\n",
    "            break\n",
    "\n",
    "        if currPower > waterMark:\n",
    "            waterMark = currPower\n",
    "            filterArray2.append(True)\n",
    "        else:\n",
    "            filterArray2.append(False)\n",
    "\n",
    "    # COMBINE TO FILTERED SIDES\n",
    "    filterArray2.reverse()\n",
    "    filterArray = filterArray1 + filterArray2\n",
    "    return powerArray[filterArray], timeArray[filterArray]\n",
    "\n",
    "# FILTER DATA SO ONLY A SUBSET OF GRADIENTS BETWEEN DATAPOINTS IS PERMITTED\n",
    "def FilterDataLimitedGradients(powerArray, timeArray):\n",
    "\n",
    "    if powerArray is None:\n",
    "        return None, None\n",
    "\n",
    "    # IN GENERAL ANLGE MUST BE BETWEEN THESE VALUES\n",
    "    angleLowerLimit = 80\n",
    "    angleUpperLimit = 90\n",
    "\n",
    "    # BUT AFTER 'continuanceLimit' CONTINUOUS VALUES HAVE BEEN ACCEPTED, THE LOWER ANGLE LIMIT IS RELAXED TO THIS VALUE BELOW\n",
    "    widerAngleLowerLimit = 70\n",
    "    continuanceLimit = 2\n",
    "\n",
    "    gradients = []\n",
    "    timeGradients = []\n",
    "    powerArray = powerArray.tolist()\n",
    "    timeArray = timeArray.tolist()\n",
    "    filterArray = []\n",
    "\n",
    "    n = len(powerArray)\n",
    "    gradientsCompliance = [0] * n\n",
    "\n",
    "    runningCount = 0\n",
    "\n",
    "    for i in range(1, n):\n",
    "        g = abs(math.degrees(math.atan((powerArray[i] - powerArray[i - 1]) / (\n",
    "                    getSingleDateTime(timeArray[i]) - getSingleDateTime(timeArray[i - 1])))))\n",
    "\n",
    "        addFlag = False\n",
    "\n",
    "        if g > angleLowerLimit and g < angleUpperLimit:\n",
    "            addFlag = True\n",
    "            runningCount += 1\n",
    "\n",
    "        elif runningCount > continuanceLimit and g > widerAngleLowerLimit:\n",
    "            addFlag = True\n",
    "\n",
    "        else:\n",
    "            runningCount = 0\n",
    "\n",
    "        if addFlag:\n",
    "            gradientsCompliance[i - 1] += 1\n",
    "            gradientsCompliance[i] += 1\n",
    "\n",
    "        if g > 85:\n",
    "            gradients.append(g)\n",
    "            timeGradients.append(timeArray[i])\n",
    "\n",
    "    if gradientsCompliance[0] == 1 and gradientsCompliance[1] == 2:\n",
    "        filterArray.append(True)\n",
    "    else:\n",
    "        filterArray.append(False)\n",
    "\n",
    "    for i in range(1, n - 1):\n",
    "        if gradientsCompliance[i] == 2:\n",
    "            filterArray.append(True)\n",
    "        elif gradientsCompliance[i] == 1 and (gradientsCompliance[i - 1] == 2 or gradientsCompliance[i + 1] == 2):\n",
    "            filterArray.append(True)\n",
    "        else:\n",
    "            filterArray.append(False)\n",
    "\n",
    "    if gradientsCompliance[n - 1] == 1 and gradientsCompliance[n - 2] == 2:\n",
    "        filterArray.append(True)\n",
    "    else:\n",
    "        filterArray.append(False)\n",
    "    \n",
    "\n",
    "    powerArray = pd.Series(powerArray)\n",
    "    timeArray = pd.Series(timeArray)\n",
    "\n",
    "    powerArray = powerArray[filterArray]\n",
    "    timeArray = timeArray[filterArray]\n",
    "\n",
    "    return powerArray, timeArray\n",
    "\n",
    "# INTEGRATE POWER OUTPUT DATA OVER EACH DAY FOR COMPARISON WITH CURTAILMENT CALCUALTIONS\n",
    "def determine_total_energy_yields(month, monthly_data, site_organiser):\n",
    "    count = 0\n",
    "    for site in site_organiser.values():\n",
    "        \n",
    "        for c in site.c_id_data.values():\n",
    "            if c.c_id not in total_energy_yield_dict.keys():\n",
    "                total_energy_yield_dict[c.c_id] = {}\n",
    "            count += 1\n",
    "            print(\"count: \" + str(count))\n",
    "            total_energy_yield_dict[c.c_id][month] = calculate_months_energy_yield(c.c_id, monthly_data)\n",
    "            \n",
    "# INTEGRATE POWER OUTPUT DATA OVER EACH DAY FOR COMPARISON WITH CURTAILMENT CALCUALTIONS\n",
    "def calculate_months_energy_yield(c_id, monthly_data):\n",
    "    c_data = monthly_data.loc[monthly_data['c_id'] == c_id]\n",
    "\n",
    "    c_data['utc_tstamp'] = c_data.apply(lambda row: remove_tstamp_ms(row['utc_tstamp']), axis=1)\n",
    "    \n",
    "    c_data = c_data.sort_values('utc_tstamp', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='first', ignore_index=False, key=None)\n",
    "\n",
    "    powerData = c_data.power.tolist()\n",
    "    timeData = c_data.utc_tstamp.tolist()\n",
    "    MeasuredEnergy = AreaUnderCurve(timeData, powerData)/1000\n",
    "    return MeasuredEnergy  \n",
    "\n",
    "# REMOVING MILISECOND VALUE IN TIMESTAMP STRINGS\n",
    "def remove_tstamp_ms(tstamp_string):\n",
    "    timeFormat1 = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    timeFormat2 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    x = datetime.strptime(tstamp_string, timeFormat1)\n",
    "    return x.strftime(timeFormat2)\n",
    "\n",
    "def AreaUnderCurve(timeData, powerData):\n",
    "    \n",
    "    energy = 0\n",
    "    \n",
    "    for i in range(0, len(timeData) - 1):\n",
    "        t2 = ChangeToTimestamp(timeData[i+1])\n",
    "        t1 = ChangeToTimestamp(timeData[i])\n",
    "        \n",
    "        dt = t2-t1\n",
    "        \n",
    "        trapArea = (dt / 3600) * 0.5 * (powerData[i] + powerData[i+1])\n",
    "        energy += trapArea\n",
    "        \n",
    "    return energy\n",
    "\n",
    "def ChangeToTimestamp(timeString):\n",
    "    element = datetime.strptime(timeString,'%Y-%m-%d %H:%M:%S')\n",
    "    return datetime.timestamp(element)\n",
    "\n",
    "# CONVERT A SINGLE STRING TIMESTAMP TO DATETIME OBJECTS\n",
    "def getSingleDateTime(d):\n",
    "    return md.date2num(datetime.strptime(d, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# GET POLYFIT OF DESIRED DEGREE, TRANSFORMING DATETIMES INTO UNIX TIMESTAMPS \n",
    "def GetPolyfit(xArray, yArray, functionDegree):\n",
    "    timestamps = xArray\n",
    "    xp = np.linspace(timestamps[0], timestamps[len(timestamps) - 1], 1000)\n",
    "    z = np.polyfit(timestamps, yArray, functionDegree)\n",
    "    polyfit = np.poly1d(z)\n",
    "\n",
    "    return polyfit\n",
    "\n",
    "# FILTER ARRAY TO INCLUDE VALUES WITHIN A CERTAIN RANGE\n",
    "def FilterArray(xArray, yArray, maxVal, minVal):\n",
    "    filter_arr = []\n",
    "    for val in xArray:\n",
    "        if val > maxVal or val < minVal:\n",
    "            filter_arr.append(False)\n",
    "        else:\n",
    "            filter_arr.append(True)\n",
    "    # NOTE: conversion between series and lists was for conveniences of used filter operator, but could be adjusted for better time performance\n",
    "    xSeries = pd.Series(xArray)\n",
    "    ySeries = pd.Series(yArray)\n",
    "\n",
    "    return xSeries[filter_arr].tolist(), ySeries[filter_arr].tolist()\n",
    "\n",
    "# CONVERT A LIST STRING TIMESTAMP TO DATETIME OBJECTS\n",
    "def getDateTimeList(List):\n",
    "    dates = [datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in List]\n",
    "    datenums = md.date2num(dates)\n",
    "    return datenums\n",
    "\n",
    "# TRANSFORM A TIMESTAMP STRING INTO A TIMESTAMP INT VALUE (SECONDS SINCE 1970)\n",
    "def getDateTime(df):\n",
    "    dates = [datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in df.ts]\n",
    "    datenums = md.date2num(dates)\n",
    "    return datenums\n",
    "\n",
    "def Change_W_to_kW(filteredPowerArray):\n",
    "    l = []\n",
    "    for x in filteredPowerArray:\n",
    "        l.append(x/1000)\n",
    "        \n",
    "    return l\n",
    "\n",
    "# INDIVIDUAL DAY/SITE ANALYSIS \n",
    "def DetermineCompliance(polyfit, graphDF, maxPower, vwLimit):\n",
    "\n",
    "    voltArray = []\n",
    "    timeArray = []\n",
    "    absoluteWattArray = []\n",
    "    relativeWattArray = []\n",
    "\n",
    "    successfulRelativeWattArray = []\n",
    "    successfulVoltArray = []\n",
    "\n",
    "    complianceArray = []\n",
    "\n",
    "    # TODO: Changing to list aided with how analysis functions were created, should be kept as pd series and adjust analysis functions for better time performance\n",
    "    dfPower = graphDF.power.tolist()\n",
    "    dfTime = graphDF.ts.tolist()\n",
    "    dfVoltage = graphDF.voltage.tolist()\n",
    "\n",
    "    for i in range(len(dfPower)):\n",
    "\n",
    "        actualPower = dfPower[i]\n",
    "        voltage = dfVoltage[i]\n",
    "        timestamp = getSingleDateTime(dfTime[i])\n",
    "\n",
    "        # Expected power for the time of day\n",
    "        expectedPower = polyfit(timestamp)\n",
    "\n",
    "        # Expected max power based on volt-watt\n",
    "        maxVWPower = voltWattCurve(voltage, vwLimit) * maxPower\n",
    "\n",
    "        # CALCULATING THE AMOUNT OF OBSERVED CURTAILMENT\n",
    "        if maxVWPower < expectedPower:\n",
    "            voltArray.append(voltage)\n",
    "            timeArray.append(timestamp)\n",
    "\n",
    "            absoluteWattArray.append(actualPower)\n",
    "            relativeWattArray.append(actualPower / maxPower)\n",
    "\n",
    "    # Perform compliance count\n",
    "    complianceCount = 0\n",
    "    bufferHighVals = 0.03 * 1000\n",
    "    bufferLowVals = 0.09 * 1000\n",
    "\n",
    "    # for i in range(len(relativeWattArray)):\n",
    "    #\n",
    "    #     relativeWatt = relativeWattArray[i]\n",
    "    #     expectedWatt = voltWattCurve(voltArray[i], vwLimit)\n",
    "    #\n",
    "    #     if relativeWatt > 0.9:\n",
    "    #         if expectedWatt - bufferHighVals < relativeWatt < expectedWatt + bufferHighVals:\n",
    "    #             complianceCount += 1\n",
    "    #             successfulRelativeWattArray.append(relativeWatt)\n",
    "    #             successfulVoltArray.append(voltArray[i])\n",
    "    #\n",
    "    #     else:\n",
    "    #         if expectedWatt - bufferLowVals < relativeWatt < expectedWatt + bufferLowVals:\n",
    "    #             complianceCount += 1\n",
    "\n",
    "    return complianceCount, voltArray, timeArray, absoluteWattArray, relativeWattArray, successfulRelativeWattArray, successfulVoltArray\n",
    "\n",
    "# VOLT-WATT LIST BASED ON V3 INVERTER SETTING AND VOLTAGE INPUT\n",
    "def voltWattCurve(v, limit):\n",
    "    if v < limit:\n",
    "        return 1\n",
    "    if v < 265:\n",
    "        return (1 - 0.8 * (v - limit) / (265 - limit))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "# RETURNS THE MAXIMUM ALLOWED W/VA AND TIME LIST BASED ON AN INVERTER'S VOLTAGE DATA\n",
    "def getMaxVoltWattCurve(maxPower, graphDF, vwLimit):\n",
    "    maxVoltWattTimeArray = []\n",
    "    maxVoltWattPowerArray = []\n",
    "\n",
    "    # TODO: SHOULD BE CHANGED TO A COLUMN WISE FUNCTION FOR BETTER TIME PERFORMANCE\n",
    "    for row in graphDF.iterrows():\n",
    "        voltage = row[1].voltage\n",
    "\n",
    "        maxVoltWattTimeArray.append(getSingleDateTime(row[1].ts))\n",
    "\n",
    "        maxVoltWattPowerArray.append(voltWattCurve(voltage, vwLimit) * maxPower / 1000)\n",
    "\n",
    "    return maxVoltWattTimeArray, maxVoltWattPowerArray\n",
    "\n",
    "# GO THROUGH THE COMBINED VW BEHAVIOUR DATA FOR ALL SITES \n",
    "def Overall_volt_watt_assessment(overall_volt_watt_dict, complaincePercentageLimit, bufferHighVals, bufferLowVals): #buf \n",
    "    bestVWLimit = 248\n",
    "    \n",
    "    countVW = 0\n",
    "    countNVW = 0\n",
    "    countNA = 0\n",
    "    \n",
    "    # AGGREGATE RESULTS FOR STATISTICAL ANALYSIS\n",
    "    for c_id in overall_volt_watt_dict.keys():\n",
    "        if c_id not in overall_volt_watt_dict.keys():\n",
    "            continue\n",
    "        res = Site_volt_watt_assessment(c_id, overall_volt_watt_dict[c_id], complaincePercentageLimit, bufferHighVals, bufferLowVals)\n",
    "        \n",
    "        if res is None:\n",
    "            countNA += 1\n",
    "            buffers_site_id_dict[bufferLowVals][\"NA\"].append(c_id)\n",
    "            print(\"\\n!!! NOT ENOUGH POINTS !!!\\n\")\n",
    "            \n",
    "        elif res == True:\n",
    "            countVW += 1\n",
    "            buffers_site_id_dict[bufferLowVals][\"VW\"].append(c_id)\n",
    "            print(\"\\n!!! VOLT-WATT !!!\\n\")\n",
    "            \n",
    "        elif res == False:\n",
    "            countNVW += 1\n",
    "            buffers_site_id_dict[bufferLowVals][\"NVW\"].append(c_id)\n",
    "            print(\"\\n!!! NON-VOLT-WATT !!!\\n\")\n",
    "\n",
    "        if res is None:\n",
    "            countNA += 1\n",
    "            site_id_dict[\"NA\"].append(c_id)\n",
    "            print(\"\\n!!! NOT ENOUGH POINTS !!!\\n\")\n",
    "\n",
    "        elif res == True:\n",
    "            countVW += 1\n",
    "            site_id_dict[\"VW\"].append(c_id)\n",
    "            print(\"\\n!!! VOLT-WATT !!!\\n\")\n",
    "\n",
    "        elif res == False:\n",
    "            countNVW += 1\n",
    "            site_id_dict[\"NVW\"].append(c_id)\n",
    "            print(\"\\n!!! NON-VOLT-WATT !!!\\n\")\n",
    "    \n",
    "    totalSites = countVW + countNVW\n",
    "    \n",
    "    \n",
    "    if totalSites == 0: totalSites = 1\n",
    "    print(\"FOR4 buffer: \" + str(bufferLowVals))\n",
    "    print(\"\\n\\nVolt-Watt sites: \" + str(countVW) + \" = \" + str2(countVW/totalSites*100) + \"%\")\n",
    "    print(\"NON Volt-Watt sites: \" + str(countNVW) + \" = \" + str2(countNVW/totalSites*100) + \"%\")\n",
    "    print(\"Not enough points to assess: \" + str(countNA))\n",
    "    print(\"Total sites: \" + str(countNA + totalSites))\n",
    "    \n",
    "# ROUND TO 2DP AND STRINGIFY A FLOAT\n",
    "def str2(num):\n",
    "    return str(round(num, 2))\n",
    "\n",
    "# DISPLAY BOTH THE POWER/VOLTAGE vs TIME PLOT, AS WELL AS W/VA vs VOLTAGE\n",
    "def Display_day(c_id, date, df, dc_cap_w, voltArray, relativeWattArray, filteredTimeArray, filteredPowerArray):\n",
    "    \n",
    "    # Returns the maxmimum permitted real power output based on the inverter's voltage conditions\n",
    "    maxVoltWattTimeArray, maxVoltWattPowerArray = getMaxVoltWattCurve(dc_cap_w, df, 250)\n",
    "    \n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.subplots_adjust(bottom=0.1)\n",
    "    plt.xticks(rotation=25)\n",
    "    ax = plt.gca()\n",
    "    xfmt = md.DateFormatter('%H:%M:%S')\n",
    "    ax.xaxis.set_major_formatter(xfmt)\n",
    "    plt.grid(False)\n",
    "\n",
    "    ax.tick_params(axis='y', labelcolor='red')\n",
    "    lns1 = ax.plot(getDateTime(df), df.voltage, 'tomato', label='Local voltage')\n",
    "    plt.ylabel(\"Voltage (V)\")\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    plt.plot(maxVoltWattTimeArray,maxVoltWattPowerArray, 'limegreen')\n",
    "    plt.plot(filteredTimeArray, filteredPowerArray, 'blue')\n",
    "    \n",
    "    lns4 = ax2.plot(getDateTime(df), df.power/1000, 'skyblue', label='Real power')\n",
    "    plt.ylabel(\"Power (kW)\")\n",
    "    plt.title(\"c_id: \" + str(c_id) + \"   Date: \" + date + \"   DC cap: \" + str(dc_cap_w))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.title(\"c_id: \" + str(c_id) + \"   Date: \" + date + \"   DC cap: \" + str(dc_cap_w))\n",
    "\n",
    "    z = np.polyfit(voltArray, relativeWattArray, 1)\n",
    "\n",
    "    slope, intercept = np.polyfit(voltArray, relativeWattArray, 1)\n",
    "    \n",
    "    p = np.poly1d(z)\n",
    "    xRange = list(range(248,260))\n",
    "    \n",
    "    plt.plot(xRange,p(xRange),\"r--\")\n",
    "    \n",
    "    plt.plot(getSampleVoltages(230, 266), getWattsCurve(250), label='Best VW limit fit')\n",
    "    plt.plot(getSampleVoltages(250, 266), getWattsCurveBuffer(250, 0.05), label='Upper buffer')\n",
    "    plt.plot(getSampleVoltages(250, 266), getWattsCurveBuffer(250, -0.05), label='Lower buffer')\n",
    "\n",
    "    plt.scatter(voltArray, relativeWattArray, c=\"purple\", marker='.', label='Inverter data')\n",
    "    plt.xlabel(\"Voltage (V)\")\n",
    "    plt.ylabel(\"Power (p.u.)\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "# RETURN A LIST OF NUMBERS WITHIN SPECIFIED RANGE\n",
    "def getSampleVoltages(a, b):\n",
    "    return list(range(a, b))\n",
    "\n",
    "# PRODUCES V-WATT REDUCTION CURVE FOR A SPECIFIC V-WATT LIMIT\n",
    "def getWattsCurve(vwLimit):\n",
    "    curve = []\n",
    "    vs = getSampleVoltages(230, 266)\n",
    "    for v in vs:\n",
    "        curve.append(voltWattCurve(v, vwLimit))\n",
    "    return curve\n",
    "\n",
    "# PRODUCES V-WATT REDUCTION CURVE FOR A SPECIFIC V-WATT LIMIT WITH A SPECIFIED BUFFER\n",
    "def getWattsCurveBuffer(vwLimit, buffer):\n",
    "    curve = []\n",
    "    vs = list(range(vwLimit, 266))\n",
    "    for v in vs:\n",
    "        curve.append(min([voltWattCurve(v, vwLimit) + buffer, 1]))\n",
    "    return curve\n",
    "\n",
    "def Site_volt_watt_assessment(c_id, site_volt_watt_dict, complaincePercentageLimit, bufferHighVals, bufferLowVals): #buf\n",
    "    bestComplianceCount = 0\n",
    "    bestCompliancePercentage = 0\n",
    "    bestVWLimit = None\n",
    "    bestVoltArray = None\n",
    "    bestRelativeWattArray = None\n",
    "    bestSuccessfulRelativeWattArray = None\n",
    "    bestSuccessfulVoltArray = None\n",
    "        \n",
    "    # BUFFER AND ANGLE SETTINGS FOR THE ANALYSIS\n",
    "    complainceCountLimit = 150\n",
    "    totalPointsCountLimit = 150\n",
    "    upperAngleLimit = -0.03\n",
    "    lowerAngleLimit = -0.06\n",
    "    \n",
    "    # VARIABLE TO CHECK IF THE ANALYSIS RAN OUT OF POINTS AT 256V OR BEFORE. \n",
    "    # IF AT 256V AND NO VW BEHAVIOUR IDENTIFIED THEN INCONCLUSIVE RESULT\n",
    "    notEnoughPointsV = 256\n",
    "    \n",
    "    print(\"\\n\\nc_id: \" + str(c_id))\n",
    "    for vwLimit in list(range(246,258)):\n",
    "        complianceCount, compliancePercentage, voltArray, relativeWattArray, successfulRelativeWattArray, successfulVoltArray = Determine_volt_watt_scatter_compliance(vwLimit, site_volt_watt_dict['v'], site_volt_watt_dict['p'], bufferHighVals, bufferLowVals)\n",
    "        if len(voltArray) == 0:\n",
    "            print(\"Ran out of points at VWLimit \" + str(vwLimit))\n",
    "            notEnoughPointsV = vwLimit\n",
    "            break\n",
    "        \n",
    "        # IF THE RESULT HAS HIGHER COMPLIANCE THAN PREVIOUS V THRESHOLD MEASURE, USE IT INSTEAD\n",
    "        if bestComplianceCount < complianceCount:\n",
    "            bestComplianceCount = complianceCount\n",
    "            bestVWLimit = vwLimit\n",
    "            bestTotalPoints = len(voltArray)\n",
    "            bestVoltArray = voltArray\n",
    "            bestRelativeWattArray = relativeWattArray\n",
    "            bestSuccessfulRelativeWattArray = successfulRelativeWattArray\n",
    "            bestSuccessfulVoltArray = successfulVoltArray\n",
    "            bestCompliancePercentage = compliancePercentage\n",
    "           \n",
    "    \n",
    "    if bestComplianceCount > 0:        \n",
    "        print(\"Best VWLimit: \" + str(bestVWLimit)) \n",
    "        \n",
    "    else:\n",
    "        print(\"No VWLimit results in any compliance\")\n",
    "    \n",
    "    if bestComplianceCount > 0 and bestTotalPoints > totalPointsCountLimit:\n",
    "        slope, intercept = np.polyfit(bestVoltArray, bestRelativeWattArray, 1)\n",
    "        print(\"Slope: \" + str(slope))\n",
    "        \n",
    "        \n",
    "        if bestComplianceCount > complainceCountLimit and bestCompliancePercentage > complaincePercentageLimit and lowerAngleLimit < slope and slope < upperAngleLimit:\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            if notEnoughPointsV < 256:\n",
    "                return None\n",
    "            else:\n",
    "                return False\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# CHECKS EACH DATA POINT TO SEE IF IT FITS WITHIN THE NECESSARY BUFFER TO BE ADDED TO THE SUCCESSFUL DATAPOINT LIST\n",
    "def Determine_volt_watt_scatter_compliance(vwLimit, originalVoltArray, originalRelativeWattArray, bufferHighVals, bufferLowVals):\n",
    "    complianceCount = 0\n",
    "    successfulRelativeWattArray = []\n",
    "    successfulVoltArray = []\n",
    "\n",
    "    # FILTER DATA TO ONLY EXAMINE VALUES HIGHER THAN THE VW LIMIT (AND LOWER THAN 1000, USED AS FilterArray FUNCTION IS USED ELSEWHERE)\n",
    "    voltArray, relativeWattArray = FilterArray(originalVoltArray, originalRelativeWattArray, 1000, vwLimit)\n",
    "\n",
    "    for i in range(len(relativeWattArray)):\n",
    "\n",
    "        relativeWatt = relativeWattArray[i]\n",
    "        expectedWatt = voltWattCurve(voltArray[i], vwLimit)\n",
    "\n",
    "        # FOR HIGHER W/VA USE A SMALLER BUFFER, AS THESE VALUES ARE MORE LIKELY TO SUFFER RANDOM VARIATIONS\n",
    "        if relativeWatt > 0.9:\n",
    "            if expectedWatt - bufferHighVals < relativeWatt < expectedWatt + bufferHighVals:\n",
    "                complianceCount += 1\n",
    "                successfulRelativeWattArray.append(relativeWatt)\n",
    "                successfulVoltArray.append(voltArray[i])\n",
    "\n",
    "        # FOR LOWER W/VA USE A LARGER BUFFER, AS THESE VALUES ARE LESS LIKELY TO SUFFER RANDOM VARIATIONS\n",
    "        else:\n",
    "            if expectedWatt - bufferLowVals < relativeWatt < expectedWatt + bufferLowVals:\n",
    "                complianceCount += 1\n",
    "                successfulRelativeWattArray.append(relativeWatt)\n",
    "                successfulVoltArray.append(voltArray[i])\n",
    "\n",
    "    compliancePercentage = 0\n",
    "    if len(voltArray) > 0:\n",
    "        compliancePercentage = complianceCount/len(voltArray)\n",
    "    return complianceCount, compliancePercentage, voltArray, relativeWattArray, successfulRelativeWattArray, successfulVoltArray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e32a75",
   "metadata": {},
   "source": [
    "# ENERGY GENERATED CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "f1d29558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_energy_generated(data_site, date):\n",
    "    sh_idx = (data_site.index.hour>= 7) & (data_site.index.hour <= 17)\n",
    "    date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    date_idx = data_site.index.date == date_dt\n",
    "    energy_generated = data_site.loc[sh_idx & date_idx, 'power'].resample('h').mean().sum()/1000\n",
    "    return energy_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d613fb",
   "metadata": {},
   "source": [
    "# CHECK CLEAR SKY DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "2050f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clear_sky_day(date):\n",
    "    dateFile = date[:4]+'_'+ date[5:7]\n",
    "    ghi = pd.read_csv(file_path +'/sl_023034_' + dateFile + \".txt\")\n",
    "    timestamp_date_string = Get_timestamp_date_string(dateFile)\n",
    "    separated_ghi_data = Separate_ghi_data(timestamp_date_string, ghi)\n",
    "    ghi_df = separated_ghi_data[date]\n",
    "    res, average_delta_y = Detect_clear_sky_day(ghi_df, 530)\n",
    "\n",
    "    if res:\n",
    "        #clear_sky_days.append(date)\n",
    "        #overall_clear_sky_days_dict[dateFile].append(date)\n",
    "        is_clear_sky_day = True\n",
    "    else:\n",
    "        is_clear_sky_day = False\n",
    "    return is_clear_sky_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f5c2c",
   "metadata": {},
   "source": [
    "# TRIPPING CURTAILMENT PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "9f754497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tripping_curtailment(is_clear_sky_day):\n",
    "    if not is_clear_sky_day:\n",
    "        tripping_response = 'Script will be available soon'\n",
    "        tripping_curt_energy = 'Script will be available soon'\n",
    "    else:\n",
    "        tripping_response = 'Script will be available soon'\n",
    "        tripping_curt_energy = 'Script will be available soon'\n",
    "    return tripping_response, tripping_curt_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db66a2f",
   "metadata": {},
   "source": [
    "# VVAr CURTAILMENT PROGRAM\n",
    "V-VAr response possibility: \n",
    "1. None\n",
    "2. Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f7ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single site data and relevant meta-data information\n",
    "def site_organize(c_id_idx, site_details, data, unique_cids):\n",
    "\n",
    "    #c_id = unique_cids.loc[c_id_idx][0]\n",
    "    c_id = c_id_idx\n",
    "    \n",
    "    polarity = site_details.loc[site_details['c_id'] == c_id, 'polarity'].values[0] # get the polarity of the site\n",
    "    ac_cap = site_details.loc[site_details['c_id'] == c_id, 'ac_cap_w'].values[0]\n",
    "    dc_cap = site_details.loc[site_details['c_id'] == c_id, 'dc_cap_w'].values[0]\n",
    "    inverter = site_details.loc[site_details['c_id'] == c_id, 'inverter_manufacturer'].values[0] + ' ' + site_details.loc[site_details['c_id'] == c_id, 'inverter_model'].values[0]\n",
    "\n",
    "    # Extract single site data and organize: \n",
    "    data_site = data[data['c_id'] == c_id].sort_index() # get the monthly data of the specific c_id\n",
    "\n",
    "    data_site['power'] = data_site['power'].values * polarity # polarity correction for real power\n",
    "    data_site['reactive_power'] = data_site['reactive_power'].values * polarity # polarity correction for reactive power\n",
    "    \n",
    "    data_site['reactive_power'] = [data_site['reactive_power'].values * -1 if np.percentile(data_site.loc[(data_site.index.hour >= 7) & (data_site.index.hour <= 17), 'reactive_power'], 75) < 0 else data_site['reactive_power'].values][0]  # double check the polarity for reactive power\n",
    "    \n",
    "    if (abs(np.percentile(data_site['reactive_power'], 99))> ac_cap) | (abs(np.percentile(data_site['reactive_power'], 1))> ac_cap): #some VAr measurements in energy format and needs to be divided by duration (i.e., 60 sec)\n",
    "        # data_site['reactive_power'] =  data_site['reactive_power'].values / data_site['duration'].values # unfortunately SolA data doesn't calculate energy according to respective duration but uses a fixed 60 sec values for energy calculation\n",
    "        data_site['reactive_power'] =  data_site['reactive_power'].values / 60\n",
    "        \n",
    "    data_site.index = pd.to_datetime([str(d)[0:19] for d in data_site.index]) ## convert index to make the df plottable (by removing the UTC conversion)\n",
    "    data_site.sort_index(ascending = True, inplace = True) # sort the index in ascending form\n",
    "    # System efficiency for calculating theoretical max output later on (use conservative loss estimates for DC power)\n",
    "    eff_inv = 0.98\n",
    "    eff_vdrop = 0.98 \n",
    "    eff_derating = 0.99  # module derating losses\n",
    "    eff_system = eff_inv * eff_vdrop * eff_derating\n",
    "\n",
    "    # Apparent power of the inverter\n",
    "    data_site['va'] = np.sqrt (data_site['power'].values**2 + data_site['reactive_power'].values**2)\n",
    "    data_site['pf'] = data_site['power']/data_site['va']\n",
    "    \n",
    "    return data_site, ac_cap, dc_cap, eff_system, inverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "a4aa4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vvar_curtailment(c_id, date, data_site,  ghi, ac_cap, dc_cap, eff_system, is_clear_sky_day):\n",
    "    date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    data_site_certain_date = data_site.loc[data_site.index.date == date_dt]\n",
    "    ghi = ghi.loc[ghi.index.date == date_dt]\n",
    "    data_site = data_site_certain_date\n",
    "    \n",
    "    # Manipulations on the original data_site to match the GHI\n",
    "    dummy = data_site.copy()\n",
    "    dummy.index = dummy.index.round('min')   # round the timestamp to nearest minute to match with the GHI\n",
    "    dummy = dummy.groupby(level = 0 ).mean()  # average same timestamp values that fall under the same minute category\n",
    "\n",
    "    data_site_complete = pd.DataFrame (index = ghi.index)  # create a data_site_complete with complete set of dates to match with GHI\n",
    "    data_site_complete = data_site_complete.join(dummy)\n",
    "    \n",
    "    # Required conditions for V-VAr curtailment\n",
    "    var_t = 100  # min VAr condition \n",
    "    duration = 60  # we have normalized all t-stamps to 60 second previously\n",
    "    va_criteria = data_site_complete['va'] >= (ac_cap - var_t)  # this is to ensure inverter VA is close to its rated capacity (this eliminates the instances of tripping)\n",
    "    var_criteria = abs(data_site_complete['reactive_power'].values) > var_t  # this is to ensure inverter is injecting/absorbing at least 100 vars\n",
    "    curt_criteria = va_criteria & var_criteria  # curtailment criteria that satisfies the two criteria above\n",
    "\n",
    "    data_curtailment = data_site_complete[curt_criteria]  # investigate curtailment only for the instances which satisfy above criteria \n",
    "    ghi_curtailment = ghi[curt_criteria]\n",
    "    \n",
    "    if not var_criteria.any():\n",
    "        vvar_response = 'None'\n",
    "    else:\n",
    "        vvar_response = 'Yes'\n",
    "        \n",
    "    # max_real_power refers to what the system could generate if it wasn't curtailed\n",
    "    #ISSUES FOR TROUBLESHOOTING LATER: SOMETIME MAX POWER IS LESS THAN POWER?\n",
    "    if is_clear_sky_day:\n",
    "        # POLYFIT METHOD TO CALCULATE THE MAX POWER WITHOUT CURTAILMENT, UNAPPLICABLE IN NON CLEAR SKY DAYS\n",
    "        circuit_day_data = data_site_complete.reset_index(level=0)\n",
    "        circuit_day_data.rename(columns = {'timestamp':'ts'}, inplace = True)\n",
    "        circuit_day_data['ts'] = circuit_day_data['ts'].astype(str)\n",
    "\n",
    "        df = circuit_day_data\n",
    "        df = SliceEndOffDF(df) # REMOVES LAST TAIL AND HEAD OF DATA AFTER IT CHANGES TO ZERO WATTS, BUT KEEPS ZERO WATT VALUES IN THE MIDDLE OF THE LIST\n",
    "\n",
    "        df = df.loc[df['power'] > 300]\n",
    "\n",
    "        # FILTER POWER DATA TO INCLUDE ONLY INCREASING VALUES FROM EACH SIDES (WHERE SIDES ARE DETERMINED BY EITHER SIDE OF THE MAX POWER VALUE)\n",
    "        powerArray, timeArray = FilterPowerData(df)\n",
    "\n",
    "        # FILTER DATA SO ONLY A SUBSET OF GRADIENTS BETWEEN DATAPOINTS IS PERMITTED\n",
    "        powerArray, timeArray = FilterDataLimitedGradients(powerArray, timeArray)\n",
    "\n",
    "        polyfit = GetPolyfit(getDateTimeList(timeArray), powerArray, 2)\n",
    "\n",
    "        polyfit_result = pd.DataFrame({\n",
    "            'timestamp' : pd.date_range(start=df['ts'].iloc[0], end=df['ts'].iloc[-1], freq='1min').astype(str)\n",
    "        })\n",
    "        polyfit_result['max_real_power'] = polyfit(getDateTimeList(polyfit_result['timestamp']))\n",
    "        polyfit_result.index = pd.to_datetime(polyfit_result['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "        polyfit_result.drop(columns = 'timestamp', inplace = True)\n",
    "\n",
    "        data_curtailment = pd.merge(data_curtailment, polyfit_result, left_index = True, right_index = True)\n",
    "        data_curtailment ['curtailment'] = data_curtailment['max_real_power'].values - data_curtailment ['power'].values\n",
    "        data_curtailment['curtailment_energy'] = data_curtailment['curtailment'].values * (duration/3600/1000) # Wmin to kWh energy: some sites have variable duration so finding curtailment in energy form (Wh)\n",
    "        \n",
    "        if not data_curtailment[data_curtailment['curtailment_energy'] > 0]['curtailment_energy'].sum() > 0:\n",
    "                data_curtailment['max_real_power'] = [min(ghi_t/1000 * dc_cap * eff_system, ac_cap) for ghi_t in ghi_curtailment['Mean global irradiance (over 1 minute) in W/sq m']]\n",
    "    \n",
    "    else: #if it is not clear sky day, use ghi to estimate maximum power without curtailmentz\n",
    "        data_curtailment['max_real_power'] = [min(ghi_t/1000 * dc_cap * eff_system, ac_cap) for ghi_t in ghi_curtailment['Mean global irradiance (over 1 minute) in W/sq m']]\n",
    "    # =============================================================================================\n",
    "    \n",
    "    data_curtailment ['curtailment'] = data_curtailment['max_real_power'].values - data_curtailment ['power'].values\n",
    "    data_curtailment['curtailment_energy'] = data_curtailment['curtailment'].values * (duration/3600/1000) # Wmin to kWh energy: some sites have variable duration so finding curtailment in energy form (Wh)\n",
    "    vvar_curt_energy = data_curtailment[data_curtailment['curtailment_energy'] > 0]['curtailment_energy'].sum()\n",
    "    return vvar_response, vvar_curt_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d0565",
   "metadata": {},
   "source": [
    "# VWATT CURTAILMENT PROGRAM\n",
    "V-VAr response possibility: \n",
    "1. Cannot be determined, not a clear sky day\n",
    "2. No V-Watt response\n",
    "3. There is V-Watt response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "d858d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vwatt_curtailment(is_clear_sky_day):\n",
    "    if not is_clear_sky_day:\n",
    "        vwatt_response = 'Script will be available soon'\n",
    "        vwatt_curt_energy = 'Script will be available soon'\n",
    "    else:\n",
    "        vwatt_response = 'Script will be available soon'\n",
    "        vwatt_curt_energy = 'Script will be available soon'\n",
    "    return vwatt_response, vwatt_curt_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94bcf3",
   "metadata": {},
   "source": [
    "# MISCELLANEOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13369b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_general_files(file_path):\n",
    "    circuit_details = pd.read_csv(file_path + r\"\\unsw_20190701_circuit_details.csv\")\n",
    "    site_details = pd.read_csv (file_path + r\"\\unsw_20190701_site_details.csv\")\n",
    "    site_details = site_details.merge(circuit_details, left_on = 'site_id', right_on = 'site_id')\n",
    "    unique_cids = pd.read_csv(file_path + r\"\\UniqueCids.csv\", index_col = 0)\n",
    "    return site_details, unique_cids\n",
    "\n",
    "def input_monthly_files(file_path, data_date_idx):\n",
    "    data_path = file_path + r\"\\processed_unsw_\" + data_date_idx + '_data_raw.csv'\n",
    "    data = pd.read_csv(data_path, index_col = 1)\n",
    "\n",
    "    # Convert timestamp to local Adelaide time\n",
    "    data.index = pd.to_datetime(data.index) # convert index from object type to datetime\n",
    "    Adelaide_local_time = pytz.timezone('Australia/Adelaide')\n",
    "    data.index = data.index.tz_localize(pytz.utc).tz_convert(Adelaide_local_time) # convert utc to local adelaide time\n",
    "    data.index.rename('Timestamp', inplace = True)\n",
    "\n",
    "    # Load GHI data\n",
    "    ghi_date_idx = data_date_idx[0:4] + '_' + data_date_idx[4:]\n",
    "    ghi_path = file_path + r\"\\sl_023034_\" + ghi_date_idx +'.txt'\n",
    "    ghi = pd.read_csv (ghi_path) \n",
    "\n",
    "    ghi['timestamp'] = pd.to_datetime(pd.DataFrame ({'year' : ghi['Year Month Day Hours Minutes in YYYY'].values, \n",
    "                                                    'month' : ghi['MM'], \n",
    "                                                    'day' : ghi['DD'], \n",
    "                                                   'hour' : ghi['HH24'], \n",
    "                                                   'minute' : ghi['MI format in Local standard time']}))\n",
    "    ghi.set_index('timestamp', inplace = True)\n",
    "    # Deal with the space characters (ghi is in object/string form at the moment)\n",
    "    ghi['Mean global irradiance (over 1 minute) in W/sq m'] = [float(ghi_t) if ghi_t.count(' ')<= 3 else np.nan for ghi_t in ghi['Mean global irradiance (over 1 minute) in W/sq m']]\n",
    "    return data, ghi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "35f27050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_result_into_dataframe(c_id, date, energy_generated, is_clear_sky_day, tripping_response, tripping_curt_energy, vvar_response, vvar_curt_energy, vwatt_response, vwatt_curt_energy):\n",
    "    summary = pd.DataFrame({\n",
    "        'c_id' : [c_id],\n",
    "        'date' : [date],\n",
    "        'energy generated (kWh)' : [energy_generated],\n",
    "        'clear sky day': [is_clear_sky_day],\n",
    "        'tripping response' : [tripping_response],\n",
    "        'tripping curtailment (kWh)' : [tripping_curt_energy],\n",
    "        'V-VAr response' : [vvar_response],\n",
    "        'V-VAr curtailment (kWh)' : [vvar_curt_energy],\n",
    "        'V-Watt response' : [vwatt_response],\n",
    "        'V-Watt curtailment (kWh)' : [vwatt_curt_energy]\n",
    "    })\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb5287",
   "metadata": {},
   "source": [
    "# MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "site_details, unique_cids, data, ghi = input_general_files(file_path = r\"C:\\Users\\samha\\Documents\\CANVAS\\data\")\n",
    "for site in site_list:\n",
    "    for month in month_list:\n",
    "    data, ghi = input_monthly_file(file_path = r\"C:\\Users\\samha\\Documents\\CANVAS\\data\")\n",
    "    organized_site_file = site_organize(c_id_idx, site_details, data, unique_cids)\n",
    "        for date in month:\n",
    "            is_clear_sky_day = check_clear_sky(date)\n",
    "            tripping_response, tripping_curtailed_energy = check_tripping_curtailment(c_id, date)\n",
    "            vvar_response, vvar_curtailed_energy = check_vvar_curtailment(c_id, date)\n",
    "            vwatt_response, vwatt_curtailed_energy = check_vwatt_curtailment(c_id, date)\n",
    "summarize_result_into_dataframe()\n",
    "show_summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d20611",
   "metadata": {},
   "source": [
    "# TRIAL FOR ONLY 1 SITE AND 1 DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "9fad7cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\samha\\Documents\\CANVAS\\data\"\n",
    "site_details, unique_cids= input_general_files(file_path)\n",
    "\n",
    "month = '201907'\n",
    "c_id_idx = 1018350709 #this is row 436 in the site id, and having the biggest vvar curtailment\n",
    "\n",
    "data, ghi = input_monthly_files(file_path, month)\n",
    "data_site, ac_cap, dc_cap, eff_system, inverter = site_organize(c_id_idx, site_details, data, unique_cids)\n",
    "\n",
    "#date = '2019-07-21' #non clear sky day\n",
    "date = '2019-07-20' #clear sky day\n",
    "\n",
    "is_clear_sky_day = check_clear_sky_day(date)\n",
    "energy_generated = check_energy_generated(data, date)\n",
    "tripping_response, tripping_curt_energy = check_tripping_curtailment(is_clear_sky_day)\n",
    "vvar_response, vvar_curt_energy = check_vvar_curtailment(c_id_idx, date, data_site, ghi, ac_cap, dc_cap, eff_system, is_clear_sky_day)\n",
    "vwatt_response, vwatt_curt_energy = check_vwatt_curtailment(is_clear_sky_day)\n",
    "summary = summarize_result_into_dataframe(c_id, date, energy_generated, is_clear_sky_day, tripping_response, tripping_curt_energy, vvar_response, vvar_curt_energy, vwatt_response, vwatt_curt_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "63c5da58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>date</th>\n",
       "      <th>energy generated (kWh)</th>\n",
       "      <th>clear sky day</th>\n",
       "      <th>tripping response</th>\n",
       "      <th>tripping curtailment (kWh)</th>\n",
       "      <th>V-VAr response</th>\n",
       "      <th>V-VAr curtailment (kWh)</th>\n",
       "      <th>V-Watt response</th>\n",
       "      <th>V-Watt curtailment (kWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018350709</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>12.023056</td>\n",
       "      <td>True</td>\n",
       "      <td>Script will be available soon</td>\n",
       "      <td>Script will be available soon</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.817819</td>\n",
       "      <td>Script will be available soon</td>\n",
       "      <td>Script will be available soon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c_id        date  energy generated (kWh)  clear sky day  \\\n",
       "0  1018350709  2019-07-20               12.023056           True   \n",
       "\n",
       "               tripping response     tripping curtailment (kWh)  \\\n",
       "0  Script will be available soon  Script will be available soon   \n",
       "\n",
       "  V-VAr response  V-VAr curtailment (kWh)                V-Watt response  \\\n",
       "0            Yes                 0.817819  Script will be available soon   \n",
       "\n",
       "        V-Watt curtailment (kWh)  \n",
       "0  Script will be available soon  "
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2278",
   "metadata": {},
   "source": [
    "# MESSY BELOW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
