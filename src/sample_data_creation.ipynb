{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813dd479",
   "metadata": {},
   "source": [
    "Script to produce 3 cleaned SolA datas and 3 GHI datas for certain date and certain site to demonstrate each mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f70b37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pytz #for timezone calculation\n",
    "import math\n",
    "import matplotlib.dates as md\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "def input_monthly_files(file_path, data_date_idx):\n",
    "    \"\"\"Open time-series D-PV data and ghi data of a certain month. Only compatible for SoLA data format.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The file location of the data\n",
    "        data_date_idx (str): The month of the files in format 'YYYYMM' eg '201907'\n",
    "\n",
    "    Returns:\n",
    "        data (df): the opened time-series D-PV data\n",
    "        ghi (df): the opened ghi data\n",
    "        \n",
    "    Originally written by Baran for VVAr Curtailment Calculation.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_path = file_path + r\"/processed_unsw_\" + data_date_idx + '_data_raw.csv'\n",
    "    data = pd.read_csv(data_path, index_col = 1)\n",
    "\n",
    "    # Convert timestamp to local Adelaide time\n",
    "    data.index = pd.to_datetime(data.index) # convert index from object type to datetime\n",
    "    Adelaide_local_time = pytz.timezone('Australia/Adelaide')\n",
    "    data.index = data.index.tz_localize(pytz.utc).tz_convert(Adelaide_local_time) # convert utc to local adelaide time\n",
    "    data.index.rename('Timestamp', inplace = True)\n",
    "\n",
    "    # Load GHI data\n",
    "    ghi_date_idx = data_date_idx[0:4] + '_' + data_date_idx[4:]\n",
    "    ghi_path = file_path + r\"/sl_023034_\" + ghi_date_idx +'.txt'\n",
    "    ghi = pd.read_csv (ghi_path) \n",
    "\n",
    "    ghi['timestamp'] = pd.to_datetime(pd.DataFrame ({'year' : ghi['Year Month Day Hours Minutes in YYYY'].values, \n",
    "                                                    'month' : ghi['MM'], \n",
    "                                                    'day' : ghi['DD'], \n",
    "                                                   'hour' : ghi['HH24'], \n",
    "                                                   'minute' : ghi['MI format in Local standard time']}))\n",
    "    ghi.set_index('timestamp', inplace = True)\n",
    "    # Deal with the space characters (ghi is in object/string form at the moment)\n",
    "    ghi['Mean global irradiance (over 1 minute) in W/sq m'] = [float(ghi_t) if ghi_t.count(' ')<= 3 else np.nan for ghi_t in ghi['Mean global irradiance (over 1 minute) in W/sq m']]\n",
    "    return data, ghi\n",
    "\n",
    "file_path = r\"C:\\Users\\samha\\Documents\\CANVAS\\data\"\n",
    "#file_path = r\"/Users/samhan/Downloads/data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d4a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_1: tripping_non_clear_sky_sample\n",
    "c_id = 1317822057\n",
    "date = '2019-09-03'\n",
    "month = date[:4] + date[5:7]\n",
    "data_sample_1, ghi_sample_1 = input_monthly_files(file_path, month)\n",
    "date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "date_filter = data_sample_1.index.date == date_dt\n",
    "site_id_filter = data_sample_1['c_id'] == c_id\n",
    "data_sample_1 = data_sample_1.loc[date_filter & site_id_filter]\n",
    "\n",
    "date_filter = ghi_sample_1.index.date == date_dt\n",
    "ghi_sample_1 = ghi_sample_1.loc[date_filter]\n",
    "\n",
    "#vvar_sample\n",
    "c_id = 1018350709\n",
    "date = '2019-07-20'\n",
    "month = date[:4] + date[5:7]\n",
    "data_sample_2, ghi_sample_2 = input_monthly_files(file_path, month)\n",
    "date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "date_filter = data_sample_2.index.date == date_dt\n",
    "site_id_filter = data_sample_2['c_id'] == c_id\n",
    "data_sample_2 = data_sample_2.loc[date_filter & site_id_filter]\n",
    "\n",
    "date_filter = ghi_sample_2.index.date == date_dt\n",
    "ghi_sample_2 = ghi_sample_2.loc[date_filter]\n",
    "\n",
    "#vwatt_sample\n",
    "c_id = 466930914\n",
    "date = '2019-08-14'\n",
    "month = date[:4] + date[5:7]\n",
    "data_sample_3, ghi_sample_3 = input_monthly_files(file_path, month)\n",
    "date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "date_filter = data_sample_3.index.date == date_dt\n",
    "site_id_filter = data_sample_3['c_id'] == c_id\n",
    "data_sample_3 = data_sample_3.loc[date_filter & site_id_filter]\n",
    "\n",
    "date_filter = ghi_sample_3.index.date == date_dt\n",
    "ghi_sample_3 = ghi_sample_3.loc[date_filter]\n",
    "\n",
    "\n",
    "\n",
    "data_sample_1.to_csv(file_path + '/data_sample_1.csv')\n",
    "data_sample_2.to_csv(file_path + '/data_sample_2.csv')\n",
    "data_sample_3.to_csv(file_path + '/data_sample_3.csv')\n",
    "\n",
    "\n",
    "ghi_sample_1.to_csv(file_path + '/ghi_sample_1.csv')\n",
    "ghi_sample_2.to_csv(file_path + '/ghi_sample_2.csv')\n",
    "ghi_sample_3.to_csv(file_path + '/ghi_sample_3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b67c980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sample 4: vwatt_sample_json_tim, good for polyfit example\n",
    "c_id = 1165442853\n",
    "date = '2020-04-13'\n",
    "month = date[:4] + date[5:7]\n",
    "data_sample_4, ghi_sample_4 = input_monthly_files(file_path, month)\n",
    "date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "date_filter = data_sample_4.index.date == date_dt\n",
    "site_id_filter = data_sample_4['c_id'] == c_id\n",
    "data_sample_4 = data_sample_4.loc[date_filter & site_id_filter]\n",
    "\n",
    "date_filter = ghi_sample_4.index.date == date_dt\n",
    "ghi_sample_4 = ghi_sample_4.loc[date_filter]\n",
    "\n",
    "data_sample_4.to_csv(file_path + '/data_sample_4.csv')\n",
    "ghi_sample_4.to_csv(file_path + '/ghi_sample_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a5b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 5: incomplete dataset\n",
    "sample_num = 5\n",
    "c_id = 1317822057\n",
    "date = '2020-03-01'\n",
    "month = date[:4] + date[5:7]\n",
    "data_sample, ghi_sample = input_monthly_files(file_path, month)\n",
    "date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "date_filter = data_sample.index.date == date_dt\n",
    "site_id_filter = data_sample['c_id'] == c_id\n",
    "data_sample = data_sample.loc[date_filter & site_id_filter]\n",
    "\n",
    "date_filter = ghi_sample.index.date == date_dt\n",
    "ghi_sample = ghi_sample.loc[date_filter]\n",
    "\n",
    "data_sample.to_csv(file_path + '/data_sample_{}.csv'.format(sample_num))\n",
    "ghi_sample.to_csv(file_path + '/ghi_sample_{}.csv'.format(sample_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a45406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 6: biggest vvar site, but don't know which date is good. Probably clear sky day in summer, January?\n",
    "# clear sky day list: '2020-01-01', '2020-01-02', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-12', '2020-01-13', '2020-01-14', '2020-01-17', '2020-01-29', '2020-01-30'\n",
    "\n",
    "#this turns out to be a very good vwatt sample\n",
    "sample_num = 6\n",
    "c_id = 898652745\n",
    "date = '2020-01-17'\n",
    "month = date[:4] + date[5:7]\n",
    "data_sample, ghi_sample = input_monthly_files(file_path, month)\n",
    "date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "date_filter = data_sample.index.date == date_dt\n",
    "site_id_filter = data_sample['c_id'] == c_id\n",
    "data_sample = data_sample.loc[date_filter & site_id_filter]\n",
    "\n",
    "date_filter = ghi_sample.index.date == date_dt\n",
    "ghi_sample = ghi_sample.loc[date_filter]\n",
    "\n",
    "data_sample.to_csv(file_path + '/data_sample_{}.csv'.format(sample_num))\n",
    "ghi_sample.to_csv(file_path + '/ghi_sample_{}.csv'.format(sample_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "595eab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 7: biggest vvar site according to Baran's script, but don't know which date is good. Probably clear sky day in summer, January?\n",
    "# clear sky day list: '2020-01-01', '2020-01-02', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-12', '2020-01-13', '2020-01-14', '2020-01-17', '2020-01-29', '2020-01-30'\n",
    "\n",
    "#this turns out to be a very good vwatt sample\n",
    "sample_num = 7\n",
    "c_id = 1365659170\n",
    "date = '2020-01-17'\n",
    "month = date[:4] + date[5:7]\n",
    "data_sample, ghi_sample = input_monthly_files(file_path, month)\n",
    "date_dt = dt.datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "date_filter = data_sample.index.date == date_dt\n",
    "site_id_filter = data_sample['c_id'] == c_id\n",
    "data_sample = data_sample.loc[date_filter & site_id_filter]\n",
    "\n",
    "date_filter = ghi_sample.index.date == date_dt\n",
    "ghi_sample = ghi_sample.loc[date_filter]\n",
    "\n",
    "data_sample.to_csv(file_path + '/data_sample_{}.csv'.format(sample_num))\n",
    "ghi_sample.to_csv(file_path + '/ghi_sample_{}.csv'.format(sample_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ba062bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = pd.read_csv(file_path + '/data_sample_1.csv')\n",
    "sample2 = pd.read_csv(file_path + '/data_sample_2.csv')\n",
    "sample3 = pd.read_csv(file_path + '/data_sample_3.csv')\n",
    "sample4 = pd.read_csv(file_path + '/data_sample_4.csv')\n",
    "sample5 = pd.read_csv(file_path + '/data_sample_5.csv')\n",
    "sample6 = pd.read_csv(file_path + '/data_sample_6.csv')\n",
    "sample7 = pd.read_csv(file_path + '/data_sample_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85ce33af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433\n",
      "1432\n",
      "1437\n",
      "1228\n",
      "22\n",
      "1497\n",
      "17272\n"
     ]
    }
   ],
   "source": [
    "print(len(sample1))\n",
    "print(len(sample2))\n",
    "print(len(sample3))\n",
    "print(len(sample4))\n",
    "print(len(sample5))\n",
    "print(len(sample6))\n",
    "print(len(sample7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea30cdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>c_id</th>\n",
       "      <th>energy</th>\n",
       "      <th>power</th>\n",
       "      <th>reactive_power</th>\n",
       "      <th>voltage</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-17 05:49:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>-113</td>\n",
       "      <td>-1.883333</td>\n",
       "      <td>5998</td>\n",
       "      <td>247.5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-17 05:50:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>-113</td>\n",
       "      <td>-1.883333</td>\n",
       "      <td>5991</td>\n",
       "      <td>247.2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17 05:51:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>-113</td>\n",
       "      <td>-1.883333</td>\n",
       "      <td>5966</td>\n",
       "      <td>247.1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-17 05:52:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>-113</td>\n",
       "      <td>-1.883333</td>\n",
       "      <td>5986</td>\n",
       "      <td>247.4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-17 05:53:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>-114</td>\n",
       "      <td>-1.900000</td>\n",
       "      <td>5985</td>\n",
       "      <td>247.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>2020-01-17 11:14:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>188223</td>\n",
       "      <td>3137.050000</td>\n",
       "      <td>13260</td>\n",
       "      <td>254.9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>2020-01-17 11:15:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>186894</td>\n",
       "      <td>3114.900000</td>\n",
       "      <td>12935</td>\n",
       "      <td>254.5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>2020-01-17 11:16:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>192079</td>\n",
       "      <td>3201.316667</td>\n",
       "      <td>12256</td>\n",
       "      <td>254.5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>2020-01-17 11:17:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>194096</td>\n",
       "      <td>3234.933333</td>\n",
       "      <td>13615</td>\n",
       "      <td>254.1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>2020-01-17 11:18:55+10:30</td>\n",
       "      <td>898652745</td>\n",
       "      <td>200017</td>\n",
       "      <td>3333.616667</td>\n",
       "      <td>14540</td>\n",
       "      <td>253.9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1497 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Timestamp       c_id  energy        power  \\\n",
       "0     2020-01-17 05:49:55+10:30  898652745    -113    -1.883333   \n",
       "1     2020-01-17 05:50:55+10:30  898652745    -113    -1.883333   \n",
       "2     2020-01-17 05:51:55+10:30  898652745    -113    -1.883333   \n",
       "3     2020-01-17 05:52:55+10:30  898652745    -113    -1.883333   \n",
       "4     2020-01-17 05:53:55+10:30  898652745    -114    -1.900000   \n",
       "...                         ...        ...     ...          ...   \n",
       "1492  2020-01-17 11:14:55+10:30  898652745  188223  3137.050000   \n",
       "1493  2020-01-17 11:15:55+10:30  898652745  186894  3114.900000   \n",
       "1494  2020-01-17 11:16:55+10:30  898652745  192079  3201.316667   \n",
       "1495  2020-01-17 11:17:55+10:30  898652745  194096  3234.933333   \n",
       "1496  2020-01-17 11:18:55+10:30  898652745  200017  3333.616667   \n",
       "\n",
       "      reactive_power  voltage  duration  \n",
       "0               5998    247.5        60  \n",
       "1               5991    247.2        60  \n",
       "2               5966    247.1        60  \n",
       "3               5986    247.4        60  \n",
       "4               5985    247.0        60  \n",
       "...              ...      ...       ...  \n",
       "1492           13260    254.9        60  \n",
       "1493           12935    254.5        60  \n",
       "1494           12256    254.5        60  \n",
       "1495           13615    254.1        60  \n",
       "1496           14540    253.9        60  \n",
       "\n",
       "[1497 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
